{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class gradientDescent:\n",
    "    def __init__(self, mu=0.3, beta1=0.8, beta2=1.5, epsilon=0.001, alpha=1, x1=1, x2=0):\n",
    "        self.mu = mu\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.x = np.array([[x1], [x2]])\n",
    "    \n",
    "    def solve(self):\n",
    "        x = self.x\n",
    "        flag = True\n",
    "        while flag:\n",
    "            x1 = x[0, 0]\n",
    "            x2 = x[1, 0]\n",
    "            f1 = x1**2 + 3*x2**2 - 4*x1 - 2*x1*x2\n",
    "            \n",
    "            d1 = 2*x1 - 4 - 2*x2\n",
    "            d2 = 6*x2 - 2*x1\n",
    "            \n",
    "            f_der = np.array([[d1], [d2]])\n",
    "            d = -f_der\n",
    "            alpha = self.alpha\n",
    "            while True:\n",
    "                y = x + alpha*d\n",
    "                print(y)\n",
    "                y1 = y[0, 0]\n",
    "                y2 = y[0, 1]\n",
    "                f2 = y1**2 + 3*y2**2 - 4*y1 - 2*y1*y2\n",
    "                temp = -alpha*np.dot(f_der, d)\n",
    "                if temp*self.mu > f1-f2:\n",
    "                    alpha = alpha*self.beta1\n",
    "                    continue\n",
    "                elif temp*(1-self.mu) < f1-f2:\n",
    "                    alpha = alpha*self.beta2\n",
    "                    continue\n",
    "                else:\n",
    "                    if abs(f1-f2) < self.epsilon:\n",
    "                        flag = False\n",
    "                    break \n",
    "            x = y + alpha*d\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = gradientDescent()\n",
    "    x = a.solve()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经历1次迭代后收敛\n",
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class newtonMethod:\n",
    "    def __init__(self, mu=0.3, beta1=0.8, beta2=1.5, epsilon=0.001, alpha=1, x1=1, x2=0):\n",
    "        self.mu = mu\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.x = np.array([[x1], [x2]])\n",
    "    \n",
    "    def solve(self):\n",
    "        x = self.x\n",
    "        flag = True\n",
    "        index = 0\n",
    "        while flag:\n",
    "            x1 = x[0, 0]\n",
    "            x2 = x[1, 0]\n",
    "            # f1 = x1**2 + 3*x2**2 - 4*x1 - 2*x1*x2\n",
    "            f1 = x1*x1 + x1*x2\n",
    "            \n",
    "            # d1 = 2*x1 - 4 - 2*x2\n",
    "            # d2 = 6*x2 - 2*x1\n",
    "            d1 = 2*x1\n",
    "            d2 = 2*x2\n",
    "            \n",
    "            f_der1 = np.array([[d1], [d2]])\n",
    "            \n",
    "            # d11 = 2\n",
    "            # d12 = -2\n",
    "            # d21 = -2\n",
    "            # d22 = 6\n",
    "            \n",
    "            d11 = 2\n",
    "            d12 = 0\n",
    "            d21 = 0\n",
    "            d22 = 2\n",
    "            \n",
    "            f_der2 = np.array([[d11, d12], [d21, d22]])\n",
    "            \n",
    "            d = np.dot(np.matrix(f_der2).I, f_der1)\n",
    "            \n",
    "            alpha = self.alpha\n",
    "            temp = np.dot(f_der1.T, d)\n",
    "            while True:\n",
    "                y = x + alpha*d\n",
    "                # print(y)\n",
    "                y1 = y[0, 0]\n",
    "                y2 = y[1, 0]\n",
    "                \n",
    "                # f2 = y1**2 + 3*y2**2 - 4*y1 - 2*y1*y2\n",
    "                f2 = y1*y1 + y2*y2\n",
    "                \n",
    "                # print(d)\n",
    "                # print(f1 + self.mu*alpha*np.dot(f_der1.T, d))\n",
    "                # print(f1 + (1-self.mu)*alpha*np.dot(f_der1.T, d))\n",
    "                # break\n",
    "                if -alpha*temp*self.mu > f1-f2:\n",
    "                    # print('太大了', alpha)\n",
    "                    # print(temp*self.mu)\n",
    "                    # print(f1-f2)\n",
    "                    alpha = alpha*self.beta1\n",
    "                    continue\n",
    "                # elif temp*(1-self.mu) < f1-f2:\n",
    "                #     print('太小了', alpha)\n",
    "                #     # print(temp*(1-self.mu))\n",
    "                #     # print(f1-f2)\n",
    "                #     alpha = alpha*self.beta2\n",
    "                #     continue\n",
    "                else:\n",
    "                    if abs(f1-f2) < self.epsilon:\n",
    "                        flag = False\n",
    "                    break\n",
    "            index += 1 \n",
    "            # print('第%d次迭代:'%(index))\n",
    "            # print(x)\n",
    "            # print(alpha)\n",
    "            # print(d)\n",
    "            x = x + alpha*d\n",
    "            # break\n",
    "        print('经历%d次迭代后收敛'%(index))\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = newtonMethod()\n",
    "    x = a.solve()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11012364123583251\n",
      "-0.779310234320707\n"
     ]
    }
   ],
   "source": [
    "x1 = 0.53106994\n",
    "x2 = 0.27813873\n",
    "print(2*(x1-1) - 400*x1*(x2-x1**2))\n",
    "print(200*(x2-x1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Train_Loss_list = []\n",
    "for i in range(10):\n",
    "    Train_Loss_list.append(1)\n",
    "\n",
    "#迭代了97次，所以x的取值范围为(0，97)，\n",
    "x1 = range(10)\n",
    "y1 = Train_Loss_list\n",
    "plt.plot(x1, y1,label=\"Train_Loss_list\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5aa5c97bcf91298a184af71150331bc5f2f8a5204c862b4ead6e12b953dcd39a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
