{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sympy import apart\n",
    "\n",
    "def pre_process(path='data/data2.txt'):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    corpus = []\n",
    "    value = re.compile(r'^[\\u4e00-\\u9fa5]{2,}$')\n",
    "    try:\n",
    "        stopwords = open('data/stopwords.txt')\n",
    "        for word in stopwords:\n",
    "            word = word.strip()\n",
    "            texts.append(word)\n",
    "    except: \n",
    "        print('error')\n",
    "    \n",
    "    try:\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        with open(path) as f:    \n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                info = line.split('_!_')\n",
    "                label = info[1]\n",
    "                if label == '102':\n",
    "                    labels.append(0)\n",
    "                elif label == '103':\n",
    "                    labels.append(1)\n",
    "                elif label == '108':\n",
    "                    labels.append(2)\n",
    "                elif label == '109':\n",
    "                    labels.append(3)\n",
    "                data1 = jieba.cut(info[3])\n",
    "                data2 = info[4].split(',')\n",
    "                data_adj = ''\n",
    "                for item in data1:\n",
    "                    if item not in texts:\n",
    "                        if value.match(item):\n",
    "                            data_adj += item + ' '\n",
    "                for item in data2:\n",
    "                    if item not in texts:\n",
    "                        if value.match(item):\n",
    "                            data_adj += item + ' '\n",
    "                corpus.append(data_adj)\n",
    "                line = f.readline()\n",
    "    except:\n",
    "        print('error')\n",
    "    \n",
    "    vectorizer=CountVectorizer()\n",
    "    transformer=TfidfTransformer()\n",
    "    tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "    weight=tfidf.toarray()\n",
    "    print(len(weight[0]))\n",
    "    \n",
    "    return weight, labels\n",
    "\n",
    "weight, labels = pre_process()\n",
    "print(len(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(100)\n",
    "pca.fit(weight)\n",
    "weight2=pca.transform(weight)\n",
    "print(len(weight2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class kmeans:\n",
    "    def __init__(self, weight, labels, clusters=4):\n",
    "        self.weight = weight\n",
    "        self.labels = labels\n",
    "        self.clusters = clusters\n",
    "        kmeans = KMeans(n_clusters=clusters)\n",
    "        self.result = kmeans.fit_predict(weight)\n",
    "    def get_result(self):\n",
    "        X = [[0 for i in range(self.clusters)] for i in range(self.clusters)]\n",
    "        for i in range(len(self.result)):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            X[predict][label] += 1\n",
    "        for i in range(self.clusters):\n",
    "            self.result[self.result==i] = X[i].index(max(X[i]))+10\n",
    "        self.result -= 10\n",
    "    def get_correct(self):\n",
    "        total = len(self.result)\n",
    "        count = 0\n",
    "        for i in range(total):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            if predict == label:\n",
    "                count += 1\n",
    "        print(count/total)\n",
    "\n",
    "a1 = kmeans(weight=weight, labels=labels)\n",
    "a1.get_result()\n",
    "a1.get_correct()\n",
    "a2 = kmeans(weight=weight2, labels=labels)\n",
    "a2.get_result()\n",
    "a2.get_correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层次聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "class agglomerativeClustering:\n",
    "    def __init__(self, weight, labels, clusters=4):\n",
    "        self.weight = weight\n",
    "        self.labels = labels\n",
    "        self.clusters = clusters\n",
    "        kmeans = AgglomerativeClustering(n_clusters=clusters)\n",
    "        self.result = kmeans.fit_predict(weight)\n",
    "    def get_result(self):\n",
    "        X = [[0 for i in range(self.clusters)] for i in range(self.clusters)]\n",
    "        for i in range(len(self.result)):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            X[predict][label] += 1\n",
    "        for i in range(self.clusters):\n",
    "            self.result[self.result==i] = X[i].index(max(X[i]))+10\n",
    "        self.result -= 10\n",
    "        print(X)\n",
    "    def get_correct(self):\n",
    "        total = len(self.result)\n",
    "        count = 0\n",
    "        for i in range(total):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            if predict == label:\n",
    "                count += 1\n",
    "        print(count/total)\n",
    "\n",
    "b1 = agglomerativeClustering(weight=weight, labels=labels)\n",
    "b1.get_result()\n",
    "b1.get_correct()\n",
    "b2 = agglomerativeClustering(weight=weight2, labels=labels)\n",
    "b2.get_result()\n",
    "b2.get_correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class dbscan:\n",
    "    def __init__(self, weight, labels, clusters=4):\n",
    "        self.weight = weight\n",
    "        self.labels = labels\n",
    "        self.clusters = clusters\n",
    "        kmeans = DBSCAN()\n",
    "        self.result = kmeans.fit_predict(weight)\n",
    "    def get_result(self):\n",
    "        X = [[0 for i in range(self.clusters)] for i in range(self.clusters)]\n",
    "        for i in range(len(self.result)):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            X[predict][label] += 1\n",
    "        for i in range(self.clusters):\n",
    "            self.result[self.result==i] = X[i].index(max(X[i]))+10\n",
    "        self.result -= 10\n",
    "        print(X)\n",
    "    def get_correct(self):\n",
    "        total = len(self.result)\n",
    "        count = 0\n",
    "        for i in range(total):\n",
    "            predict = self.result[i]\n",
    "            label = labels[i]\n",
    "            if predict == label:\n",
    "                count += 1\n",
    "        print(count/total)\n",
    "\n",
    "c1 = dbscan(weight=weight, labels=labels)\n",
    "c1.get_result()\n",
    "c1.get_correct()\n",
    "c2 = dbscan(weight=weight2, labels=labels)\n",
    "c2.get_result()\n",
    "c2.get_correct()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "414894a69326f3f6f0d879a0c415983bdd565510f9119cc362e056dc12c18af4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
